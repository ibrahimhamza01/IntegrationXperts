                  epoch,             train/loss,  metrics/accuracy_top1,  metrics/accuracy_top5,               val/loss,                 lr/pg0,                 lr/pg1,                 lr/pg2
                      1,                 0.7267,                0.91991,                      1,                0.66473,             0.00023765,             0.00023765,             0.00023765
                      2,                 0.3459,                0.94517,                      1,                0.62768,              0.0004521,              0.0004521,              0.0004521
                      3,                0.28146,                0.96488,                      1,                0.60119,               0.000643,               0.000643,               0.000643
                      4,                0.23832,                0.96235,                      1,                0.60395,             0.00060797,             0.00060797,             0.00060797
                      5,                 0.2175,                0.96943,                      1,                0.59351,             0.00057263,             0.00057263,             0.00057263
                      6,                0.17549,                0.97221,                      1,                 0.5889,             0.00053728,             0.00053728,             0.00053728
                      7,                0.15899,                0.97094,                      1,                0.58479,             0.00050194,             0.00050194,             0.00050194
                      8,                0.15446,                0.97297,                      1,                0.58752,              0.0004666,              0.0004666,              0.0004666
                      9,                0.13885,                0.97448,                      1,                0.58102,             0.00043126,             0.00043126,             0.00043126
                     10,                0.13976,                0.97499,                      1,                0.58209,             0.00039591,             0.00039591,             0.00039591
                     11,                0.12482,                 0.9712,                      1,                0.58874,             0.00036057,             0.00036057,             0.00036057
                     12,                0.12195,                 0.9717,                      1,                0.58862,             0.00032523,             0.00032523,             0.00032523
                     13,                0.12587,                0.97473,                      1,                0.58316,             0.00028988,             0.00028988,             0.00028988
                     14,                0.11304,                0.97322,                      1,                  0.585,             0.00025454,             0.00025454,             0.00025454
                     15,                0.10595,                0.97549,                      1,                0.58308,              0.0002192,              0.0002192,              0.0002192
                     16,                0.10616,                0.97473,                      1,                0.58182,             0.00018385,             0.00018385,             0.00018385
                     17,                0.11138,                0.97524,                      1,                0.58319,             0.00014851,             0.00014851,             0.00014851
                     18,                0.09924,                0.97372,                      1,                0.58278,             0.00011317,             0.00011317,             0.00011317
                     19,                0.09649,                0.97549,                      1,                 0.5812,             7.7826e-05,             7.7826e-05,             7.7826e-05
                     20,                0.09367,                0.97499,                      1,                0.58155,             4.2483e-05,             4.2483e-05,             4.2483e-05
