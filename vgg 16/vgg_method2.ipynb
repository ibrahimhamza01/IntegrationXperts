{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "-HYKYp9N9ZuJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os,random\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nr_y3jwT9ZuM",
        "outputId": "4fb912f3-f0da-480d-987e-1ed670c371cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxJAkvBy9v5o",
        "outputId": "544a4124-3b06-41bc-da28-589f025a369c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "1t8Jp4979ZuO"
      },
      "outputs": [],
      "source": [
        "# Train_dir, Test_dir\n",
        "base_dir = '/content/drive/MyDrive/Colab Notebooks/cat_dog/train'\n",
        "train_dir = '/content/drive/MyDrive/Colab Notebooks/cat_dog/train'\n",
        "test_dir = '/content/drive/MyDrive/Colab Notebooks/cat_dog/test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhoPIVyd9ZuP",
        "outputId": "51166c07-2a7d-4338-e43a-2d6950f84b24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total images found: 557\n"
          ]
        }
      ],
      "source": [
        "# Initialize an empty list to hold the image file paths\n",
        "train_list = []\n",
        "\n",
        "# Walk through the train directory\n",
        "for root, dirs, files in os.walk(train_dir):\n",
        "    for file in files:\n",
        "        # Check if the file is an image by its extension\n",
        "        if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
        "            # Construct the full file path and append it to train_list\n",
        "            full_path = os.path.join(root, file)\n",
        "            train_list.append(full_path)\n",
        "\n",
        "# Print the number of images found and the list\n",
        "print(f'Total images found: {len(train_list)}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5HLKwLw9ZuP",
        "outputId": "a6f362e9-d132-47e1-8e2b-7de53223e424"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total images found in test directory: 140\n"
          ]
        }
      ],
      "source": [
        "# Initialize an empty list to hold the image file paths for testing\n",
        "test_list = []\n",
        "\n",
        "# Walk through the test directory\n",
        "for root, dirs, files in os.walk(test_dir):\n",
        "    for file in files:\n",
        "        # Check if the file is an image by its extension\n",
        "        if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
        "            # Construct the full file path and append it to test_list\n",
        "            full_path = os.path.join(root, file)\n",
        "            test_list.append(full_path)\n",
        "\n",
        "# Print the number of images found and the list\n",
        "print(f'Total images found in test directory: {len(test_list)}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cn0oZVdm9ZuQ",
        "outputId": "3c351fc2-18f5-40fe-ba9f-27ec93f73d61"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/Colab Notebooks/cat_dog/test/cats/cat_140.jpg',\n",
              " '/content/drive/MyDrive/Colab Notebooks/cat_dog/test/cats/cat_190.jpg',\n",
              " '/content/drive/MyDrive/Colab Notebooks/cat_dog/test/cats/cat_342.jpg',\n",
              " '/content/drive/MyDrive/Colab Notebooks/cat_dog/test/cats/cat_113.jpg',\n",
              " '/content/drive/MyDrive/Colab Notebooks/cat_dog/test/cats/cat_268.jpg']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Image_Id is contained in filepath\n",
        "test_list[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "gSl9H__K9ZuR",
        "outputId": "c68ac96c-7278-4ee6-bb10-1af577c1465f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cats'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get Label\n",
        "train_list[0].split('/')[-2].split('.')[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "gOgjuvxk9ZuR"
      },
      "outputs": [],
      "source": [
        "# Divide Train, Valid Data\n",
        "train_list, val_list = train_test_split(train_list, test_size=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "IG91xU5M9ZuR"
      },
      "outputs": [],
      "source": [
        "# Data Augumentation\n",
        "class ImageTransform():\n",
        "\n",
        "    def __init__(self, resize, mean, std):\n",
        "        self.data_transform = {\n",
        "            'train': transforms.Compose([\n",
        "                transforms.RandomResizedCrop(resize, scale=(0.5, 1.0)),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean, std)\n",
        "            ]),\n",
        "            'val': transforms.Compose([\n",
        "                transforms.Resize(256),\n",
        "                transforms.CenterCrop(resize),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean, std)\n",
        "            ]),\n",
        "            'test': transforms.Compose([\n",
        "                transforms.Resize(256),\n",
        "                transforms.CenterCrop(resize),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean, std)\n",
        "            ])\n",
        "        }\n",
        "\n",
        "    def __call__(self, img, phase):\n",
        "        return self.data_transform[phase](img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "fZayI2bA9ZuR"
      },
      "outputs": [],
      "source": [
        "# Dataset\n",
        "class DogvsCatDataset(data.Dataset):\n",
        "\n",
        "    def __init__(self, file_list, transform=None, phase='train'):\n",
        "        self.file_list = file_list\n",
        "        self.transform = transform\n",
        "        self.phase = phase\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        img_path = self.file_list[idx]\n",
        "        img = Image.open(img_path).convert('RGB')  # Ensure the image is in RGB format\n",
        "        img_transformed = self.transform(img, self.phase)\n",
        "\n",
        "        # Get Label\n",
        "        label = train_list[0].split('/')[-2].split('.')[0]\n",
        "        if label == 'dogs':\n",
        "            label = 1\n",
        "        elif label == 'cats':\n",
        "            label = 0\n",
        "\n",
        "        return img_transformed, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emzSuXCU9ZuS",
        "outputId": "93a05ce6-d120-4c85-c67e-97631b964dce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Config\n",
        "size = 224\n",
        "mean = (0.485, 0.456, 0.406)\n",
        "std = (0.229, 0.224, 0.225)\n",
        "batch_size = 32\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RS5B23_Q9ZuS",
        "outputId": "8558ac08-3390-446c-fb30-8023e385dcd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Operation Check\n",
            "torch.Size([3, 224, 224])\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "# Dataset\n",
        "train_dataset = DogvsCatDataset(train_list, transform=ImageTransform(size, mean, std), phase='train')\n",
        "val_dataset = DogvsCatDataset(val_list, transform=ImageTransform(size, mean, std), phase='val')\n",
        "test_dataset = DogvsCatDataset(test_list, transform=ImageTransform(size, mean, std), phase='test')\n",
        "\n",
        "# Operation Check\n",
        "print('Operation Check')\n",
        "index = 0\n",
        "print(train_dataset.__getitem__(index)[0].size())\n",
        "print(train_dataset.__getitem__(index)[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngjZ9xjW9ZuS",
        "outputId": "a1eb827c-e814-48db-ab71-36486d9bf042"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Operation Check\n",
            "torch.Size([32, 3, 224, 224])\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n"
          ]
        }
      ],
      "source": [
        "# DataLoader\n",
        "train_dataloader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_dataloader = data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "dataloader_dict = {'train': train_dataloader, 'val': val_dataloader, 'test':test_dataloader}\n",
        "\n",
        "# Operation Check\n",
        "print('Operation Check')\n",
        "batch_iterator = iter(train_dataloader)\n",
        "inputs, label = next(batch_iterator)\n",
        "print(inputs.size())\n",
        "print(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "ZzVTOw129ZuS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from collections import OrderedDict\n",
        "\n",
        "class VGG16(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(VGG16, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU())\n",
        "\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU())\n",
        "\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "        self.layer5 = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU())\n",
        "\n",
        "        self.layer6 = nn.Sequential(\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU())\n",
        "\n",
        "        self.layer7 = nn.Sequential(\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "        self.layer8 = nn.Sequential(\n",
        "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU())\n",
        "\n",
        "        self.layer9 = nn.Sequential(\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU())\n",
        "\n",
        "        self.layer10 = nn.Sequential(\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "        self.layer11 = nn.Sequential(\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU())\n",
        "\n",
        "        self.layer12 = nn.Sequential(\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU())\n",
        "\n",
        "        self.layer13 = nn.Sequential(\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(7*7*512, 4096),\n",
        "            nn.ReLU())\n",
        "\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU())\n",
        "\n",
        "        self.fc2 = nn.Sequential(\n",
        "            nn.Linear(4096, num_classes))\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = self.layer5(out)\n",
        "        out = self.layer6(out)\n",
        "        out = self.layer7(out)\n",
        "        out = self.layer8(out)\n",
        "        out = self.layer9(out)\n",
        "        out = self.layer10(out)\n",
        "        out = self.layer11(out)\n",
        "        out = self.layer12(out)\n",
        "        out = self.layer13(out)\n",
        "\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        out = self.fc1(out)\n",
        "        out = self.fc2(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def print_parameters(self):\n",
        "        total_params = 0\n",
        "        layer_params = OrderedDict()\n",
        "\n",
        "        # Calculate the total parameters for each type of layer\n",
        "        for name, param in self.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                layer_name = name.split('.')[0]\n",
        "                layer_params[layer_name] = layer_params.get(layer_name, 0) + param.numel()\n",
        "\n",
        "        print(f\"{'Layer Name':<25} {'Parameters':>15}\")\n",
        "        print('-' * 50)\n",
        "        for layer_name, params in layer_params.items():\n",
        "            total_params += params\n",
        "            print(f\"{layer_name:<25} {params:>15}\")\n",
        "\n",
        "        print('-' * 50)\n",
        "        print(f\"{'Total Parameters':<35} {total_params:>15}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCs-88lR9ZuT",
        "outputId": "176bcae4-2e95-4abd-e5f7-beabe0a53d02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layer Name                     Parameters\n",
            "--------------------------------------------------\n",
            "layer1                               1920\n",
            "layer2                              37056\n",
            "layer3                              74112\n",
            "layer4                             147840\n",
            "layer5                             295680\n",
            "layer6                             590592\n",
            "layer7                             590592\n",
            "layer8                            1181184\n",
            "layer9                            2360832\n",
            "layer10                           2360832\n",
            "layer11                           2360832\n",
            "layer12                           2360832\n",
            "layer13                           2360832\n",
            "fc                              102764544\n",
            "fc1                              16781312\n",
            "fc2                                 40970\n",
            "--------------------------------------------------\n",
            "Total Parameters                          134309962\n"
          ]
        }
      ],
      "source": [
        "model = VGG16(num_classes=10)\n",
        "model.print_parameters()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqjfjEqH9ZuT",
        "outputId": "0221d452-c71a-4c60-d519-6b05b8530983"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VGG16(\n",
            "  (layer1): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (layer5): Sequential(\n",
            "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (layer6): Sequential(\n",
            "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (layer7): Sequential(\n",
            "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (layer8): Sequential(\n",
            "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (layer9): Sequential(\n",
            "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (layer10): Sequential(\n",
            "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (layer11): Sequential(\n",
            "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (layer12): Sequential(\n",
            "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (layer13): Sequential(\n",
            "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (fc1): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (fc2): Sequential(\n",
            "    (0): Linear(in_features=4096, out_features=2, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "num_classes = 2\n",
        "num_epochs = 20\n",
        "batch_size = 16\n",
        "learning_rate = 0.005\n",
        "\n",
        "model = VGG16(num_classes).to(device)\n",
        "print(model)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.005, momentum = 0.9)\n",
        "\n",
        "\n",
        "# Train the model\n",
        "total_step = len(train_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azDeQoAM9ZuT",
        "outputId": "bcdf2b78-e551-4d0c-b5ca-05495c11ebfd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/20], Step [16/16], Loss: 0.0000\n",
            "Accuracy of the network on the 5000 validation images: 100.0 %\n",
            "Epoch [2/20], Step [16/16], Loss: 0.0000\n",
            "Accuracy of the network on the 5000 validation images: 100.0 %\n",
            "Epoch [3/20], Step [16/16], Loss: 0.0000\n",
            "Accuracy of the network on the 5000 validation images: 100.0 %\n",
            "Epoch [4/20], Step [16/16], Loss: 0.0000\n",
            "Accuracy of the network on the 5000 validation images: 100.0 %\n",
            "Epoch [5/20], Step [16/16], Loss: 0.0000\n",
            "Accuracy of the network on the 5000 validation images: 100.0 %\n",
            "Epoch [6/20], Step [16/16], Loss: 0.0000\n",
            "Accuracy of the network on the 5000 validation images: 100.0 %\n",
            "Epoch [7/20], Step [16/16], Loss: 0.0000\n",
            "Accuracy of the network on the 5000 validation images: 100.0 %\n",
            "Epoch [8/20], Step [16/16], Loss: 0.0000\n",
            "Accuracy of the network on the 5000 validation images: 100.0 %\n",
            "Epoch [9/20], Step [16/16], Loss: 0.0000\n",
            "Accuracy of the network on the 5000 validation images: 100.0 %\n",
            "Epoch [10/20], Step [16/16], Loss: 0.0000\n",
            "Accuracy of the network on the 5000 validation images: 100.0 %\n",
            "Epoch [11/20], Step [16/16], Loss: 0.0000\n",
            "Accuracy of the network on the 5000 validation images: 100.0 %\n",
            "Epoch [12/20], Step [16/16], Loss: 0.0000\n",
            "Accuracy of the network on the 5000 validation images: 100.0 %\n",
            "Epoch [13/20], Step [16/16], Loss: 0.0000\n",
            "Accuracy of the network on the 5000 validation images: 100.0 %\n",
            "Epoch [14/20], Step [16/16], Loss: 0.0000\n",
            "Accuracy of the network on the 5000 validation images: 100.0 %\n",
            "Epoch [15/20], Step [16/16], Loss: 0.0000\n",
            "Accuracy of the network on the 5000 validation images: 100.0 %\n",
            "Epoch [16/20], Step [16/16], Loss: 0.0000\n",
            "Accuracy of the network on the 5000 validation images: 100.0 %\n",
            "Epoch [17/20], Step [16/16], Loss: 0.0000\n",
            "Accuracy of the network on the 5000 validation images: 100.0 %\n",
            "Epoch [18/20], Step [16/16], Loss: 0.0000\n",
            "Accuracy of the network on the 5000 validation images: 100.0 %\n",
            "Epoch [19/20], Step [16/16], Loss: 0.0000\n",
            "Accuracy of the network on the 5000 validation images: 100.0 %\n",
            "Epoch [20/20], Step [16/16], Loss: 0.0000\n",
            "Accuracy of the network on the 5000 validation images: 100.0 %\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_dataloader):\n",
        "        # Move tensors to the configured device\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
        "\n",
        "    # Validation\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in val_dataloader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            del images, labels, outputs\n",
        "\n",
        "        print('Accuracy of the network on the {} validation images: {} %'.format(5000, 100 * correct / total))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvrzM92cCDIs",
        "outputId": "38a57f23-14d1-48f8-a16d-7300e5c92345"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 100.0 %\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_dataloader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        del images, labels, outputs\n",
        "\n",
        "    print('Accuracy of the network on the {} test images: {} %'.format(10000, 100 * correct / total))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
